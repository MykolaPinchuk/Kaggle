{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Machine Learning Foundation\n\n## Course 5, Part e: CNN DEMO","metadata":{"run_control":{"marked":true}}},{"cell_type":"code","source":"from tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\n#from keras.datasets import cifar10\n#from keras.preprocessing.image import ImageDataGenerator\n#from keras.models import Sequential\n#from keras.layers import Dense, Dropout, Activation, Flatten\n#from keras.layers import Conv2D, MaxPooling2D\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.optimizers import RMSprop\nimport time\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.layers import BatchNormalization","metadata":{"execution":{"iopub.status.busy":"2022-02-07T03:40:16.942171Z","iopub.execute_input":"2022-02-07T03:40:16.942429Z","iopub.status.idle":"2022-02-07T03:40:16.948052Z","shell.execute_reply.started":"2022-02-07T03:40:16.942400Z","shell.execute_reply":"2022-02-07T03:40:16.947374Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# The data, shuffled and split between train and test sets:\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n## Each image is a 32 x 32 x 3 numpy array\nprint(x_train[444].shape)\nprint(y_train[444])\n#plt.imshow(x_train[444]);","metadata":{"execution":{"iopub.status.busy":"2022-02-07T03:40:20.093073Z","iopub.execute_input":"2022-02-07T03:40:20.093754Z","iopub.status.idle":"2022-02-07T03:40:20.840604Z","shell.execute_reply.started":"2022-02-07T03:40:20.093712Z","shell.execute_reply":"2022-02-07T03:40:20.839768Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"x_train shape: (50000, 32, 32, 3)\n50000 train samples\n10000 test samples\n(32, 32, 3)\n[9]\n","output_type":"stream"}]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n\nnum_classes = 10\n\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)\n\n# now instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position\nprint(y_train[444])\n\n# As before, let's make everything float and scale\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T03:40:22.363562Z","iopub.execute_input":"2022-02-07T03:40:22.364114Z","iopub.status.idle":"2022-02-07T03:40:22.623273Z","shell.execute_reply.started":"2022-02-07T03:40:22.364075Z","shell.execute_reply":"2022-02-07T03:40:22.622543Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n(50000, 32, 32, 3)\n(50000, 10)\n(10000, 32, 32, 3)\n(10000, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Let's build model_1: 2-1, 5x5 architecture.\n\nmodel_1 = Sequential()\n\n\n## 5x5 convolution with 2x2 stride and 32 filters\nmodel_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n                 input_shape=x_train.shape[1:]))\nmodel_1.add(Activation('relu'))\n\n## Another 5x5 convolution with 2x2 stride and 32 filters\nmodel_1.add(Conv2D(32, (5, 5), strides = (2,2)))\nmodel_1.add(Activation('relu'))\n\n## 2x2 max pooling reduces to 3 x 3 x 32\nmodel_1.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_1.add(Dropout(0.25))\n\n## Flatten turns 3x3x32 into 288x1\nmodel_1.add(Flatten())\nmodel_1.add(Dense(512))\nmodel_1.add(Activation('relu'))\nmodel_1.add(Dropout(0.5))\nmodel_1.add(Dense(num_classes))\nmodel_1.add(Activation('softmax'))\n\n#model_1.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T03:40:25.028059Z","iopub.execute_input":"2022-02-07T03:40:25.028692Z","iopub.status.idle":"2022-02-07T03:40:25.088409Z","shell.execute_reply.started":"2022-02-07T03:40:25.028633Z","shell.execute_reply":"2022-02-07T03:40:25.087723Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"We still have 181K parameters, even though this is a \"small\" model.\n","metadata":{}},{"cell_type":"code","source":"batch_size = 32\n\n# initiate RMSprop optimizer\nopt = RMSprop(lr=0.0005, decay=1e-6)\n\n# Let's train the model using RMSprop\nmodel_1.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\n\n#t = time.time()\nmodel_1.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=10,\n              validation_data=(x_test, y_test),\n              shuffle=True)\n\n#print('elpsed time is', time.time()-t)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T03:40:28.434973Z","iopub.execute_input":"2022-02-07T03:40:28.435224Z","iopub.status.idle":"2022-02-07T03:41:36.268309Z","shell.execute_reply.started":"2022-02-07T03:40:28.435198Z","shell.execute_reply":"2022-02-07T03:41:36.267641Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Epoch 1/10\n1563/1563 [==============================] - 7s 4ms/step - loss: 1.7201 - accuracy: 0.3717 - val_loss: 1.5315 - val_accuracy: 0.4634\nEpoch 2/10\n1563/1563 [==============================] - 6s 4ms/step - loss: 1.4456 - accuracy: 0.4791 - val_loss: 1.3281 - val_accuracy: 0.5359\nEpoch 3/10\n1563/1563 [==============================] - 7s 4ms/step - loss: 1.3398 - accuracy: 0.5190 - val_loss: 1.2908 - val_accuracy: 0.5397\nEpoch 4/10\n1563/1563 [==============================] - 6s 4ms/step - loss: 1.2614 - accuracy: 0.5520 - val_loss: 1.1898 - val_accuracy: 0.5820\nEpoch 5/10\n1563/1563 [==============================] - 7s 4ms/step - loss: 1.2159 - accuracy: 0.5700 - val_loss: 1.1618 - val_accuracy: 0.5813\nEpoch 6/10\n1563/1563 [==============================] - 7s 4ms/step - loss: 1.1813 - accuracy: 0.5844 - val_loss: 1.0812 - val_accuracy: 0.6191\nEpoch 7/10\n1563/1563 [==============================] - 7s 4ms/step - loss: 1.1524 - accuracy: 0.5928 - val_loss: 1.0554 - val_accuracy: 0.6296\nEpoch 8/10\n1563/1563 [==============================] - 7s 4ms/step - loss: 1.1258 - accuracy: 0.6052 - val_loss: 1.0671 - val_accuracy: 0.6250\nEpoch 9/10\n1563/1563 [==============================] - 6s 4ms/step - loss: 1.1106 - accuracy: 0.6137 - val_loss: 1.1353 - val_accuracy: 0.6090\nEpoch 10/10\n1563/1563 [==============================] - 7s 4ms/step - loss: 1.0977 - accuracy: 0.6176 - val_loss: 1.0400 - val_accuracy: 0.6386\n","output_type":"stream"},{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f6e942dd8d0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Exercise\nOur previous model had the structure:\n\nConv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n\n(with appropriate activation functions and dropouts)\n\n1. Build a more complicated model with the following pattern:\n- Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n\n- Use strides of 1 for all convolutional layers.\n\n2. How many parameters does your model have?  How does that compare to the previous model?\n\n3. Train it for 5 epochs.  What do you notice about the training time, loss and accuracy numbers (on both the training and validation sets)?\n\n5. Try different structures and run times, and see how accurate your model can be.\n","metadata":{}},{"cell_type":"code","source":"# Let's build model_2: 2-1-2-1, 3x3 architecture\n\nmodel_2 = Sequential()\n\nmodel_2.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=x_train.shape[1:]))\nmodel_2.add(Activation('relu'))\nmodel_2.add(Conv2D(32, (3, 3)))\nmodel_2.add(Activation('relu'))\nmodel_2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2.add(Dropout(0.2))\n\nmodel_2.add(Conv2D(64, (3, 3), padding='same'))\nmodel_2.add(Activation('relu'))\nmodel_2.add(Conv2D(64, (3, 3)))\nmodel_2.add(Activation('relu'))\nmodel_2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2.add(Dropout(0.2))\n\nmodel_2.add(Flatten())\nmodel_2.add(Dense(512))\nmodel_2.add(Activation('relu'))\nmodel_2.add(Dropout(0.4))\nmodel_2.add(Dense(num_classes))\nmodel_2.add(Activation('softmax'))\n\n#model_2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T03:41:41.999765Z","iopub.execute_input":"2022-02-07T03:41:42.000538Z","iopub.status.idle":"2022-02-07T03:41:42.082614Z","shell.execute_reply.started":"2022-02-07T03:41:42.000486Z","shell.execute_reply":"2022-02-07T03:41:42.081908Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# initiate RMSprop optimizer\nopt_2 = RMSprop(lr=0.0005)\n\n# Let's train the model using RMSprop\nmodel_2.compile(loss='categorical_crossentropy',\n              optimizer=opt_2,\n              metrics=['accuracy'])\n\nmodel_2.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=10,\n              validation_data=(x_test, y_test),\n              shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T03:41:46.942774Z","iopub.execute_input":"2022-02-07T03:41:46.943223Z","iopub.status.idle":"2022-02-07T03:43:12.795236Z","shell.execute_reply.started":"2022-02-07T03:41:46.943185Z","shell.execute_reply":"2022-02-07T03:43:12.794495Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Epoch 1/10\n1563/1563 [==============================] - 10s 6ms/step - loss: 1.5455 - accuracy: 0.4390 - val_loss: 1.2157 - val_accuracy: 0.5682\nEpoch 2/10\n1563/1563 [==============================] - 8s 5ms/step - loss: 1.1269 - accuracy: 0.6032 - val_loss: 0.9887 - val_accuracy: 0.6498\nEpoch 3/10\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.9464 - accuracy: 0.6682 - val_loss: 0.9100 - val_accuracy: 0.6893\nEpoch 4/10\n1563/1563 [==============================] - 9s 5ms/step - loss: 0.8476 - accuracy: 0.7052 - val_loss: 0.8004 - val_accuracy: 0.7245\nEpoch 5/10\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7865 - accuracy: 0.7276 - val_loss: 0.8864 - val_accuracy: 0.7132\nEpoch 6/10\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7564 - accuracy: 0.7428 - val_loss: 0.8091 - val_accuracy: 0.7501\nEpoch 7/10\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7431 - accuracy: 0.7497 - val_loss: 0.8048 - val_accuracy: 0.7416\nEpoch 8/10\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7414 - accuracy: 0.7524 - val_loss: 0.7792 - val_accuracy: 0.7361\nEpoch 9/10\n1563/1563 [==============================] - 8s 5ms/step - loss: 0.7420 - accuracy: 0.7525 - val_loss: 0.7877 - val_accuracy: 0.7435\nEpoch 10/10\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7434 - accuracy: 0.7539 - val_loss: 0.7899 - val_accuracy: 0.7483\n","output_type":"stream"},{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f6e94039510>"},"metadata":{}}]},{"cell_type":"code","source":"# Let's build model_3: 2-1-2-1-1-1, 3x3 architecture, lower dropouts\n\nmodel_3 = Sequential()\n\nmodel_3.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=x_train.shape[1:]))\nmodel_3.add(Activation('relu'))\nmodel_3.add(Conv2D(32, (3, 3)))\nmodel_3.add(Activation('relu'))\nmodel_3.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_3.add(Dropout(0.2))\n\nmodel_3.add(Conv2D(64, (3, 3), padding='same'))\nmodel_3.add(Activation('relu'))\nmodel_3.add(Conv2D(64, (3, 3)))\nmodel_3.add(Activation('relu'))\nmodel_3.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_3.add(Dropout(0.2))\n\nmodel_3.add(Conv2D(128, (3, 3)))\nmodel_3.add(Activation('relu'))\nmodel_3.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_3.add(Dropout(0.2))\n\nmodel_3.add(Flatten())\nmodel_3.add(Dense(1024))\nmodel_3.add(Activation('relu'))\nmodel_3.add(Dropout(0.4))\nmodel_3.add(Dense(num_classes))\nmodel_3.add(Activation('softmax'))\n\n#model_3.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T03:43:19.005492Z","iopub.execute_input":"2022-02-07T03:43:19.005785Z","iopub.status.idle":"2022-02-07T03:43:19.112069Z","shell.execute_reply.started":"2022-02-07T03:43:19.005755Z","shell.execute_reply":"2022-02-07T03:43:19.111374Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# initiate RMSprop optimizer\nopt_3 = RMSprop(lr=0.0005)\n\n# Let's train the model using RMSprop\nmodel_3.compile(loss='categorical_crossentropy',\n              optimizer=opt_3,\n              metrics=['accuracy'])\n\nmodel_3.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=10,\n              validation_data=(x_test, y_test),\n              shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T03:43:24.385918Z","iopub.execute_input":"2022-02-07T03:43:24.386621Z","iopub.status.idle":"2022-02-07T03:45:49.379131Z","shell.execute_reply.started":"2022-02-07T03:43:24.386580Z","shell.execute_reply":"2022-02-07T03:45:49.378267Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Epoch 1/10\n1563/1563 [==============================] - 11s 6ms/step - loss: 1.6356 - accuracy: 0.3968 - val_loss: 1.4106 - val_accuracy: 0.4895\nEpoch 2/10\n1563/1563 [==============================] - 9s 6ms/step - loss: 1.2231 - accuracy: 0.5626 - val_loss: 1.0911 - val_accuracy: 0.6141\nEpoch 3/10\n1563/1563 [==============================] - 9s 5ms/step - loss: 1.0501 - accuracy: 0.6300 - val_loss: 1.0125 - val_accuracy: 0.6526\nEpoch 4/10\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.9358 - accuracy: 0.6739 - val_loss: 0.9052 - val_accuracy: 0.6885\nEpoch 5/10\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.8584 - accuracy: 0.7025 - val_loss: 0.7549 - val_accuracy: 0.7395\nEpoch 6/10\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.8153 - accuracy: 0.7199 - val_loss: 0.8004 - val_accuracy: 0.7260\nEpoch 7/10\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7842 - accuracy: 0.7318 - val_loss: 0.7959 - val_accuracy: 0.7318\nEpoch 8/10\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7678 - accuracy: 0.7394 - val_loss: 0.7710 - val_accuracy: 0.7375\nEpoch 9/10\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7636 - accuracy: 0.7446 - val_loss: 0.7993 - val_accuracy: 0.7399\nEpoch 10/10\n1563/1563 [==============================] - 9s 6ms/step - loss: 0.7623 - accuracy: 0.7456 - val_loss: 0.7049 - val_accuracy: 0.7666\n","output_type":"stream"},{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f6e93683d50>"},"metadata":{}}]},{"cell_type":"markdown","source":"---\n### Machine Learning Foundation (C) 2020 IBM Corporation","metadata":{}}]}