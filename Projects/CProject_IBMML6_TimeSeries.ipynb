{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This is Final Exam for IBM Time Series course.\n# I use monthly vw market data.\n# Not everything works here =(","metadata":{"execution":{"iopub.status.busy":"2022-02-11T16:26:19.7186Z","iopub.execute_input":"2022-02-11T16:26:19.718925Z","iopub.status.idle":"2022-02-11T16:26:19.723228Z","shell.execute_reply.started":"2022-02-11T16:26:19.718889Z","shell.execute_reply":"2022-02-11T16:26:19.72232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install statsmodels==0.11.0\n!pip install pmdarima","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:04:13.593353Z","iopub.execute_input":"2022-02-11T19:04:13.593903Z","iopub.status.idle":"2022-02-11T19:04:41.137281Z","shell.execute_reply.started":"2022-02-11T19:04:13.593867Z","shell.execute_reply":"2022-02-11T19:04:41.136202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport statsmodels.api as sm\nimport seaborn as sns\nplt.style.use('seaborn-white')\nfrom datetime import datetime\nimport tensorflow as tf\nimport warnings\nwarnings.simplefilter(action='ignore')\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, SimpleRNN, LSTM, Activation, Dropout\nimport math\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import mean_squared_error\n\nprint(sm.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:04:41.139256Z","iopub.execute_input":"2022-02-11T19:04:41.139545Z","iopub.status.idle":"2022-02-11T19:04:48.646994Z","shell.execute_reply.started":"2022-02-11T19:04:41.139514Z","shell.execute_reply":"2022-02-11T19:04:48.646018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/monthly-market-returns/mMKT.CSV'\ndf = pd.read_csv(path)\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:04:48.648868Z","iopub.execute_input":"2022-02-11T19:04:48.649413Z","iopub.status.idle":"2022-02-11T19:04:48.674153Z","shell.execute_reply.started":"2022-02-11T19:04:48.649365Z","shell.execute_reply":"2022-02-11T19:04:48.673389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:04:48.67623Z","iopub.execute_input":"2022-02-11T19:04:48.676729Z","iopub.status.idle":"2022-02-11T19:04:48.693189Z","shell.execute_reply.started":"2022-02-11T19:04:48.676692Z","shell.execute_reply":"2022-02-11T19:04:48.692442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.date=pd.to_datetime(df.date,format='%Y%m')\ndf.date=df.date.dt.strftime(\"%Y-%m\")","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:04:48.69472Z","iopub.execute_input":"2022-02-11T19:04:48.695159Z","iopub.status.idle":"2022-02-11T19:04:48.721084Z","shell.execute_reply.started":"2022-02-11T19:04:48.695124Z","shell.execute_reply":"2022-02-11T19:04:48.720086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.set_index('date', inplace=True)\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:04:48.722616Z","iopub.execute_input":"2022-02-11T19:04:48.722923Z","iopub.status.idle":"2022-02-11T19:04:48.751944Z","shell.execute_reply.started":"2022-02-11T19:04:48.722889Z","shell.execute_reply":"2022-02-11T19:04:48.750894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()\nsns.lineplot(x=df.index, y='mkt', data=df)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:04:48.753521Z","iopub.execute_input":"2022-02-11T19:04:48.754298Z","iopub.status.idle":"2022-02-11T19:05:01.566942Z","shell.execute_reply.started":"2022-02-11T19:04:48.754247Z","shell.execute_reply":"2022-02-11T19:05:01.566145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# testing stationarity and seasonality\nimport statsmodels.tsa.stattools as ts\n\nresults = ts.adfuller(df)\nresults\n# ts is stationary.","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:05:01.568353Z","iopub.execute_input":"2022-02-11T19:05:01.569158Z","iopub.status.idle":"2022-02-11T19:05:01.651503Z","shell.execute_reply.started":"2022-02-11T19:05:01.569115Z","shell.execute_reply":"2022-02-11T19:05:01.650631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# forecasting using ARIMA\n\n# first, see acf/pacf\n\nsm.tsa.graphics.plot_acf(df.mkt, lags=24, zero=False);","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:05:01.653298Z","iopub.execute_input":"2022-02-11T19:05:01.653886Z","iopub.status.idle":"2022-02-11T19:05:01.892728Z","shell.execute_reply.started":"2022-02-11T19:05:01.653832Z","shell.execute_reply":"2022-02-11T19:05:01.891854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sm.tsa.graphics.plot_pacf(df.mkt, lags=24, zero=False);","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:05:01.895086Z","iopub.execute_input":"2022-02-11T19:05:01.895357Z","iopub.status.idle":"2022-02-11T19:05:02.110649Z","shell.execute_reply.started":"2022-02-11T19:05:01.895328Z","shell.execute_reply":"2022-02-11T19:05:02.109807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# acf and pacf look like noise, not sure which arma to use.\n\nfrom pmdarima.arima import auto_arima\n\ntrain = df[0:900]\ntest = df[900:]","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:05:02.111987Z","iopub.execute_input":"2022-02-11T19:05:02.112299Z","iopub.status.idle":"2022-02-11T19:05:02.228175Z","shell.execute_reply.started":"2022-02-11T19:05:02.112257Z","shell.execute_reply":"2022-02-11T19:05:02.227253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# try to autodetect arima order, use this: https://towardsdatascience.com/time-series-forecasting-using-auto-arima-in-python-bb83e49210cd\n\narima_model = auto_arima(train, start_p=0, start_q=1, d=0, max_p=12, max_d=0, max_q=12, seasonal=False, n_fits=50, steepwise=False)\narima_model","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:05:02.229755Z","iopub.execute_input":"2022-02-11T19:05:02.230072Z","iopub.status.idle":"2022-02-11T19:05:04.247207Z","shell.execute_reply.started":"2022-02-11T19:05:02.230031Z","shell.execute_reply":"2022-02-11T19:05:04.24595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from statsmodels.tsa.arima_model import ARIMA\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\npredictions = []\nactual = []\n\n#len(df.mkt)\n\nfor i in np.arange(10, len(df.mkt)):\n    arima_model = ARIMA(df.mkt[0:i], order=(0,0,1))\n    arima_model_fit = arima_model.fit(disp=0)\n    yhat = arima_model_fit.forecast()\n    predictions.append(yhat[0])\n    actual.append(df.mkt[i])\n    \nwarnings.resetwarnings()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:05:04.249335Z","iopub.execute_input":"2022-02-11T19:05:04.249794Z","iopub.status.idle":"2022-02-11T19:05:49.828407Z","shell.execute_reply.started":"2022-02-11T19:05:04.249744Z","shell.execute_reply":"2022-02-11T19:05:49.827693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.concatenate(predictions, axis=0)\nprint(predictions[0:10])\nprint(actual[0:10])\nnp.mean((actual-predictions)**2)\nnp.mean((actual-predictions)**2)","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:05:49.832377Z","iopub.execute_input":"2022-02-11T19:05:49.833138Z","iopub.status.idle":"2022-02-11T19:05:49.843355Z","shell.execute_reply.started":"2022-02-11T19:05:49.833094Z","shell.execute_reply":"2022-02-11T19:05:49.842461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(predictions))\nprint(len(actual))\nprint(np.mean((actual-predictions)**2))\nprint(np.mean((actual-np.full((len(actual)), 0.5))**2))","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:41:55.57064Z","iopub.execute_input":"2022-02-11T19:41:55.571465Z","iopub.status.idle":"2022-02-11T19:41:55.57922Z","shell.execute_reply.started":"2022-02-11T19:41:55.571431Z","shell.execute_reply":"2022-02-11T19:41:55.578592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define functions, needed for RNN forecasting\n\ndef get_keras_format_series(series):\n    \"\"\"Convert a series to a numpy array of shape [n_obs, time_steps, features]\"\"\"\n    \n    series = np.array(series)\n    return series.reshape(series.shape[0], series.shape[1], 1)\n\ndef get_train_test_data(df, series_name, input_periods, test_periods):\n    \"\"\"\n    Utility processing function that splits an hourly time series into \n    train and test with keras-friendly format, according to user-specified\n    choice of shape.    \n    \n    arguments\n    ---------\n    df (dataframe): dataframe with time series columns\n    series_name (string): column name in df\n    input_hours (int): length of sequence input to network \n    test_hours (int): length of held-out terminal sequence\n    \n    returns\n    ---------\n    tuple: train_X, test_X_init, train_y, test_y     \n    \"\"\"\n    \n    forecast_series = df[series_name]\n    train = forecast_series[:-test_periods] \n    test = forecast_series[-test_periods:] \n\n    train_X, train_y = [], []\n\n    # range 0 through # of train samples - input_hours # This is to create many samples with corresponding\n    for i in range(0, train.shape[0]-input_periods): \n        train_X.append(train[i:i+input_periods]) # each training sample is of length input hours\n        train_y.append(train[i+input_periods]) # each y is just the next step after training sample\n\n    train_X = get_keras_format_series(train_X) # format our new training set to keras format\n    train_y = np.array(train_y) # make sure y is an array to work properly with keras\n    \n    # The set that we had held out for testing (must be same length as original train input)\n    test_X_init = test[:input_periods] \n    test_y = test[input_periods:] # test_y is remaining values from test set\n    \n    return train_X, test_X_init, train_y, test_y","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:05:49.853663Z","iopub.execute_input":"2022-02-11T19:05:49.854523Z","iopub.status.idle":"2022-02-11T19:05:49.866773Z","shell.execute_reply.started":"2022-02-11T19:05:49.854412Z","shell.execute_reply":"2022-02-11T19:05:49.865869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# forecasting using RNN\n\ntrain_X, test_X_init, train_y, test_y = get_train_test_data(df, 'mkt', 12, 24)\nprint('Training input shape: {}'.format(train_X.shape))\nprint('Training output shape: {}'.format(train_y.shape))\nprint('Test input shape: {}'.format(test_X_init.shape))\nprint('Test output shape: {}'.format(test_y.shape))","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:05:49.868087Z","iopub.execute_input":"2022-02-11T19:05:49.868432Z","iopub.status.idle":"2022-02-11T19:05:49.942967Z","shell.execute_reply.started":"2022-02-11T19:05:49.868386Z","shell.execute_reply":"2022-02-11T19:05:49.942094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_SimpleRNN(train_X, train_y, cell_units, epochs):\n    \"\"\"\n    Fit Simple RNN to data train_X, train_y \n    \n    arguments\n    ---------\n    train_X (array): input sequence samples for training \n    train_y (list): next step in sequence targets\n    cell_units (int): number of hidden units for RNN cells  \n    epochs (int): number of training epochs   \n    \"\"\"\n\n    # initialize model\n    model = Sequential() \n    \n    # construct an RNN layer with specified number of hidden units\n    # per cell and desired sequence input format \n    model.add(SimpleRNN(cell_units, input_shape=(train_X.shape[1],1)))\n    \n    # add an output layer to make final predictions \n    model.add(Dense(1))\n    \n    # define the loss function / optimization strategy, and fit\n    # the model with the desired number of passes over the data (epochs) \n    model.compile(loss='mean_squared_error', optimizer='adam')\n    model.fit(train_X, train_y, epochs=epochs, batch_size=64, verbose=0)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:05:49.944427Z","iopub.execute_input":"2022-02-11T19:05:49.944687Z","iopub.status.idle":"2022-02-11T19:05:49.951747Z","shell.execute_reply.started":"2022-02-11T19:05:49.944658Z","shell.execute_reply":"2022-02-11T19:05:49.951019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_rnn = fit_SimpleRNN(train_X, train_y, cell_units=10, epochs=300)\n# model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:13:51.3883Z","iopub.execute_input":"2022-02-11T19:13:51.389441Z","iopub.status.idle":"2022-02-11T19:14:07.586063Z","shell.execute_reply.started":"2022-02-11T19:13:51.389398Z","shell.execute_reply":"2022-02-11T19:14:07.585269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(X_init, n_steps, model):\n    \"\"\"\n    Given an input series matching the model's expected format,\n    generates model's predictions for next n_steps in the series      \n    \"\"\"\n    \n    #X_init = X_init.copy().reshape(1,-1,1)\n    #X_init = np.array(X_init)\n    X_init = np.array(test_X_init.copy())\n    X_init = X_init.reshape(1,12,1)\n\n    preds = []\n    \n    # iteratively take current input sequence, generate next step pred,\n    # and shift input sequence forward by a step (to end with latest pred).\n    # collect preds as we go.\n    for _ in range(n_steps):\n        pred = model.predict(X_init)\n        preds.append(pred)\n        X_init[:,:-1,:] = X_init[:,1:,:] # replace first 11 values with 2nd through 12th\n        X_init[:,-1,:] = pred # replace 12th value with prediction\n    \n    preds = np.array(preds).reshape(-1,1)\n    \n    return preds\n\ndef predict_and_plot(X_init, y, model, title):\n    \"\"\"\n    Given an input series matching the model's expected format,\n    generates model's predictions for next n_steps in the series,\n    and plots these predictions against the ground truth for those steps \n    \n    arguments\n    ---------\n    X_init (array): initial sequence, must match model's input shape\n    y (array): true sequence values to predict, follow X_init\n    model (keras.models.Sequential): trained neural network\n    title (string): plot title   \n    \"\"\"\n    \n    y_preds = predict(test_X_init, n_steps=len(y), model=model) # predict through length of y\n    # Below ranges are to set x-axes\n    start_range = range(1, test_X_init.shape[0]+1) #starting at one through to length of test_X_init to plot X_init\n    predict_range = range(test_X_init.shape[0], 24)  #predict range is going to be from end of X_init to length of test_hours\n    \n    #using our ranges we plot X_init\n    plt.plot(start_range, test_X_init)\n    #and test and actual preds\n    plt.plot(predict_range, test_y, color='orange')\n    plt.plot(predict_range, y_preds, color='teal', linestyle='--')\n    \n    plt.title(title)\n    plt.legend(['Initial Series','Target Series','Predictions'])","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:07:02.467622Z","iopub.execute_input":"2022-02-11T19:07:02.468256Z","iopub.status.idle":"2022-02-11T19:07:02.482045Z","shell.execute_reply.started":"2022-02-11T19:07:02.468204Z","shell.execute_reply":"2022-02-11T19:07:02.480419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tX = np.array(test_X_init.copy())\ntX=tX.reshape(1,12,1)\ntX.shape","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:07:05.548472Z","iopub.execute_input":"2022-02-11T19:07:05.548756Z","iopub.status.idle":"2022-02-11T19:07:05.557393Z","shell.execute_reply.started":"2022-02-11T19:07:05.548728Z","shell.execute_reply":"2022-02-11T19:07:05.556533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_rnn.predict(np.array(tX))","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:07:06.868816Z","iopub.execute_input":"2022-02-11T19:07:06.869135Z","iopub.status.idle":"2022-02-11T19:07:07.396687Z","shell.execute_reply.started":"2022-02-11T19:07:06.869098Z","shell.execute_reply":"2022-02-11T19:07:07.395878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predict(test_X_init, 12, model_rnn)\npredict_and_plot(test_X_init, test_y, model_rnn, 'PM Series: Test Data and Simple RNN Predictions')","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:14:42.749404Z","iopub.execute_input":"2022-02-11T19:14:42.750068Z","iopub.status.idle":"2022-02-11T19:14:43.786229Z","shell.execute_reply.started":"2022-02-11T19:14:42.750027Z","shell.execute_reply":"2022-02-11T19:14:43.785292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_rnn = predict(test_X_init, 12, model_rnn)\nprint(predictions_rnn)\nprint(test_y)\nprint(np.mean((np.array(test_y)-predictions_rnn)**2))\nprint(np.mean((np.array(test_y)-0.5)**2))","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:14:50.807254Z","iopub.execute_input":"2022-02-11T19:14:50.807573Z","iopub.status.idle":"2022-02-11T19:14:51.467171Z","shell.execute_reply.started":"2022-02-11T19:14:50.807538Z","shell.execute_reply":"2022-02-11T19:14:51.466281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# forecasting using LSTM\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_LSTM(train_X, train_y, cell_units, epochs):\n    \"\"\"\n    Fit LSTM to data train_X, train_y \n    \n    arguments\n    ---------\n    train_X (array): input sequence samples for training \n    train_y (list): next step in sequence targets\n    cell_units (int): number of hidden units for LSTM cells  \n    epochs (int): number of training epochs   \n    \"\"\"\n    \n    # initialize model\n    model = Sequential() \n    \n    # construct a LSTM layer with specified number of hidden units\n    # per cell and desired sequence input format \n    model.add(LSTM(cell_units, input_shape=(train_X.shape[1],1))) #,return_sequences= True))\n    #model.add(LSTM(cell_units_l2, input_shape=(train_X.shape[1],1)))\n    \n    # add an output layer to make final predictions \n    model.add(Dense(1))\n    \n    # define the loss function / optimization strategy, and fit\n    # the model with the desired number of passes over the data (epochs) \n    model.compile(loss='mean_squared_error', optimizer='adam')\n    model.fit(train_X, train_y, epochs=epochs, batch_size=64, verbose=0)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:15:07.180077Z","iopub.execute_input":"2022-02-11T19:15:07.180392Z","iopub.status.idle":"2022-02-11T19:15:07.18836Z","shell.execute_reply.started":"2022-02-11T19:15:07.180362Z","shell.execute_reply":"2022-02-11T19:15:07.187339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_lstm = fit_LSTM(train_X, train_y, cell_units=30, epochs=1500) \n\npredict_and_plot(test_X_init, test_y, model_lstm, \n                 'PM_Nongzhanguan Series: Test Data and LSTM Predictions')\n\npredictions_lstm = predict(test_X_init, 12, model_lstm)\n#print(predictions_rnn)\n#print(test_y)\nprint(np.mean((np.array(test_y)-predictions_lstm)**2))\nprint(np.mean((np.array(test_y)-0.5)**2))","metadata":{"execution":{"iopub.status.busy":"2022-02-11T19:51:14.164101Z","iopub.execute_input":"2022-02-11T19:51:14.164447Z","iopub.status.idle":"2022-02-11T19:54:41.980101Z","shell.execute_reply.started":"2022-02-11T19:51:14.164415Z","shell.execute_reply":"2022-02-11T19:54:41.979327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# forecasting using transformer?","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}