{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"##################################################################################################\n### This script is ML Classification template, which should be applicable to most MLC projects ###\n##################################################################################################\n\n\"\"\"Structure of the script:\n1. Load all needed libraries and functions.\n2. Load data, do preliminary data exploration.\n3. [Optional] Transform skewed variables.\n4. Trnasform features depending on their type. OHC.\n5. Create subsamples.\n6. Do scaling.\n7. Fit models, selecting hyperparameters via CV grid search.\n8. Evaluate performance of the selected models on test sample.\n\"\"\"\n# it is not the latest ML template. See HackerRank_ML_availability_final for later version.","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:00:07.940034Z","iopub.execute_input":"2022-03-23T15:00:07.940816Z","iopub.status.idle":"2022-03-23T15:00:07.946838Z","shell.execute_reply.started":"2022-03-23T15:00:07.940773Z","shell.execute_reply":"2022-03-23T15:00:07.94613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### 1.Load main libraries ###\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import svm\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom xgboost import XGBRegressor, XGBClassifier\n\npd.set_option('display.max_columns', 20)\npd.set_option('mode.chained_assignment', None)\npd.set_option('display.expand_frame_repr', False)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T20:06:49.836355Z","iopub.execute_input":"2022-03-29T20:06:49.836902Z","iopub.status.idle":"2022-03-29T20:06:51.452142Z","shell.execute_reply.started":"2022-03-29T20:06:49.836797Z","shell.execute_reply":"2022-03-29T20:06:51.451369Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def draw_histograms(df, variables, n_rows, n_cols):\n    # stolen from https://stackoverflow.com/questions/29530355/plotting-multiple-histograms-in-grid\n    fig=plt.figure()\n    for i, var_name in enumerate(variables):\n        ax=fig.add_subplot(n_rows,n_cols,i+1)\n        df[var_name].hist(bins=10,ax=ax)\n        ax.set_title(var_name+\" Distribution\")\n    fig.tight_layout()  \n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:00:11.589325Z","iopub.execute_input":"2022-03-23T15:00:11.589588Z","iopub.status.idle":"2022-03-23T15:00:11.59475Z","shell.execute_reply.started":"2022-03-23T15:00:11.589557Z","shell.execute_reply":"2022-03-23T15:00:11.59388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"### 2.Load data ###\n\npath = '../input/titanic/train.csv'\ndf = pd.read_csv(path) # titanic_fullsample\nprint(df.shape)\ndf.drop(columns=['Name', 'Ticket', 'Cabin'],inplace=True)\ndf.loc[df.Age.isnull(),'Age'] = df.Age.median()\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:00:15.580193Z","iopub.execute_input":"2022-03-23T15:00:15.580692Z","iopub.status.idle":"2022-03-23T15:00:15.613092Z","shell.execute_reply.started":"2022-03-23T15:00:15.580654Z","shell.execute_reply":"2022-03-23T15:00:15.612141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.describe())\n# sns.pairplot(df[['Survived', 'Pclass', 'Age', 'Fare']])\ndraw_histograms(df, df.columns, 4, 3)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:00:21.52828Z","iopub.execute_input":"2022-03-23T15:00:21.529099Z","iopub.status.idle":"2022-03-23T15:00:22.408595Z","shell.execute_reply.started":"2022-03-23T15:00:21.529039Z","shell.execute_reply":"2022-03-23T15:00:22.408027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% 3.Transform some skewed variables ###\n\ndf['Fare'] = np.log1p(df.Fare)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T15:00:26.610266Z","iopub.execute_input":"2022-03-23T15:00:26.610562Z","iopub.status.idle":"2022-03-23T15:00:26.61679Z","shell.execute_reply.started":"2022-03-23T15:00:26.61053Z","shell.execute_reply":"2022-03-23T15:00:26.615611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% 4.Transform features depending on their type ###\n\n# this is very important for ML application, where there are hundreds of features.\n# If there are less than 20 features, can use standard approach.\n# my approach of tackling one feature a time is not scalable. \n\n# use intuition to trim range or ordinary variables \n# can skip this step in general, since it is not scalable when number of features grows.\ndf.loc[df.SibSp>2,'SibSp']=3\ndf.loc[df.Parch>2,'Parch']=3\n\n# identify binary and categorical variables\ndf_uniques = pd.DataFrame([[i, len(df[i].unique())] for i in df.columns], columns=['Variable', 'Unique Values']).set_index('Variable')\nprint(df_uniques)\n\nbinary_variables = list(df_uniques[df_uniques['Unique Values'] == 2].index)\ncategorical_variables = list(df_uniques[(6 >= df_uniques['Unique Values']) & (df_uniques['Unique Values'] > 2)].index)\nnumeric_variables = list(set(df.columns) - set(categorical_variables) - set(binary_variables))\nprint('Binary variables are ', binary_variables)\nprint('Categorical variables are ', categorical_variables)\nprint('Numeric variables are ', numeric_variables)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:31:40.286008Z","iopub.execute_input":"2022-03-23T14:31:40.286608Z","iopub.status.idle":"2022-03-23T14:31:40.301491Z","shell.execute_reply.started":"2022-03-23T14:31:40.286558Z","shell.execute_reply":"2022-03-23T14:31:40.30064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ohc for binary variables #\nlb = LabelBinarizer()\nbinary_variables.remove('Survived')\nfor column in binary_variables:\n    df[column] = lb.fit_transform(df[column])\n\n# ohc for categorical variables #\ndf = pd.get_dummies(df, columns = categorical_variables, drop_first=True)\n\nprint(df.shape)\nprint(df.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:31:47.35103Z","iopub.execute_input":"2022-03-23T14:31:47.352077Z","iopub.status.idle":"2022-03-23T14:31:47.372631Z","shell.execute_reply.started":"2022-03-23T14:31:47.352021Z","shell.execute_reply":"2022-03-23T14:31:47.3719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %% 5.Creating subsamples ###\n\ny = df['Survived']\nX = df.drop(columns=['Survived'])\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:31:58.320809Z","iopub.execute_input":"2022-03-23T14:31:58.321579Z","iopub.status.idle":"2022-03-23T14:31:58.330166Z","shell.execute_reply.started":"2022-03-23T14:31:58.321531Z","shell.execute_reply":"2022-03-23T14:31:58.329382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %% 6.scaling numeric variables ###\n\ndraw_histograms(X_train, numeric_variables, 2, 3)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:36:00.491347Z","iopub.execute_input":"2022-03-23T14:36:00.492242Z","iopub.status.idle":"2022-03-23T14:36:00.895493Z","shell.execute_reply.started":"2022-03-23T14:36:00.492203Z","shell.execute_reply":"2022-03-23T14:36:00.894658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss = StandardScaler()\n\nfor column in [numeric_variables]:\n    X_train[column] = ss.fit_transform(X_train[column])\n    X_test[column] = ss.transform(X_test[column])","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:35:27.135156Z","iopub.execute_input":"2022-03-23T14:35:27.136275Z","iopub.status.idle":"2022-03-23T14:35:27.152306Z","shell.execute_reply.started":"2022-03-23T14:35:27.136225Z","shell.execute_reply":"2022-03-23T14:35:27.151269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####################\n### 7.Fit models ###\n####################\n\n#%% Logistic regression ###\n\ngrid_values = {'penalty': ['l2'], 'C': list(np.arange(1,10.5,0.5))}\nlr = LogisticRegression()\nmodel_lr = GridSearchCV(lr, param_grid=grid_values, cv = 10)\nmodel_lr.fit(X_train, y_train)\nprint(model_lr.best_score_, model_lr.best_params_)\n\n# model_lr.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:46:04.770111Z","iopub.execute_input":"2022-03-23T14:46:04.770784Z","iopub.status.idle":"2022-03-23T14:46:07.281292Z","shell.execute_reply.started":"2022-03-23T14:46:04.770732Z","shell.execute_reply":"2022-03-23T14:46:07.280268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% KNN ###\n\ngrid_values = dict(n_neighbors=np.arange(1,40))\nknnm = KNeighborsClassifier()   \nmodel_knn = GridSearchCV(knnm, param_grid=grid_values, cv = 10)\nmodel_knn.fit(X_train, y_train)\nprint(model_knn.best_score_, model_knn.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:46:15.307979Z","iopub.execute_input":"2022-03-23T14:46:15.308257Z","iopub.status.idle":"2022-03-23T14:46:18.744699Z","shell.execute_reply.started":"2022-03-23T14:46:15.308231Z","shell.execute_reply":"2022-03-23T14:46:18.743795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% SVM ###\n\ngrid_values = {'C': np.arange(0.05, 1, 0.05)} \nsvmm = svm.SVC(kernel='rbf')\nmodel_svm = GridSearchCV(svmm, param_grid=grid_values, cv = 10)\nmodel_svm.fit(X_train, y_train)\nprint(model_svm.best_score_, model_svm.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:46:28.158184Z","iopub.execute_input":"2022-03-23T14:46:28.158488Z","iopub.status.idle":"2022-03-23T14:46:32.475612Z","shell.execute_reply.started":"2022-03-23T14:46:28.158458Z","shell.execute_reply":"2022-03-23T14:46:32.47452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% RF ###\n\n# may look here: https://www.geeksforgeeks.org/hyperparameter-tuning/\n\ngrid_values = [{'max_depth': list(range(2, 9, 2)), 'max_features': list(np.arange(0.3,0.71,0.1))}]\nrfc = RandomForestClassifier(random_state=42)\nmodel_rf = GridSearchCV(rfc, grid_values, cv = 5, scoring='accuracy')\nmodel_rf.fit(X_train, y_train)\nprint(model_rf.best_score_, model_rf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:52:28.83156Z","iopub.execute_input":"2022-03-23T14:52:28.831976Z","iopub.status.idle":"2022-03-23T14:52:45.291467Z","shell.execute_reply.started":"2022-03-23T14:52:28.831943Z","shell.execute_reply":"2022-03-23T14:52:45.290568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% XGBoost ###\n# run this code only on Kaggle with GPU\n\nestimator = XGBClassifier(\n    nthread=4,\n    seed=42,\n    use_label_encoder=False\n)\n\nparameters = {\n    'max_depth': range (2, 5, 1),\n    'n_estimators': range(5, 50, 5),\n    'learning_rate': [0.01, 0.05, 0.1, 0.15]\n}\n\ngrid_search = GridSearchCV(\n    estimator=estimator,\n    param_grid=parameters,\n    scoring = 'roc_auc',\n    n_jobs = 10,\n    cv = 10,\n    verbose=True\n)\n\ngrid_search.fit(X_train, y_train, eval_metric='rmse')\nprint(grid_search.best_score_, grid_search.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T19:19:31.696233Z","iopub.execute_input":"2022-02-08T19:19:31.696661Z","iopub.status.idle":"2022-02-08T19:20:39.710327Z","shell.execute_reply.started":"2022-02-08T19:19:31.696624Z","shell.execute_reply":"2022-02-08T19:20:39.707744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% 8.Evaluate performance oos ###\n\nyhat_lm = model_lr.predict(X_test)\nyhat_knn = model_knn.predict(X_test)\nyhat_svm = model_svm.predict(X_test)\nyhat_rf = model_rf.predict(X_test)\n#yhat_bt = grid_search.predict(X_test)\nprint('Accuracy of logistic regression is ', 1-(np.abs(yhat_lm-y_test)).mean())\nprint('Accuracy of KNN is ', 1-(np.abs(yhat_knn-y_test)).mean())\nprint('Accuracy of SVM is ', 1-(np.abs(yhat_svm-y_test)).mean())\nprint('Accuracy of RF is ', 1-(np.abs(yhat_rf-y_test)).mean())\n#print('Accuracy of Boosted Tree is ', 1-(np.abs(yhat_bt-y_test)).mean())","metadata":{"execution":{"iopub.status.busy":"2022-03-23T14:53:51.839901Z","iopub.execute_input":"2022-03-23T14:53:51.840172Z","iopub.status.idle":"2022-03-23T14:53:51.881892Z","shell.execute_reply.started":"2022-03-23T14:53:51.840143Z","shell.execute_reply":"2022-03-23T14:53:51.880878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}