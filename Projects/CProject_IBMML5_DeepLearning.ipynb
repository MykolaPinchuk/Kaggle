{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Machine Learning Foundation\n\n## Course 5, Part e: CNN DEMO","metadata":{"run_control":{"marked":true}}},{"cell_type":"code","source":"### this is a final project for IBM ML Deep Learning course ###\n\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.layers import BatchNormalization\n\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-02-07T18:19:44.714407Z","iopub.execute_input":"2022-02-07T18:19:44.71469Z","iopub.status.idle":"2022-02-07T18:19:51.121332Z","shell.execute_reply.started":"2022-02-07T18:19:44.714606Z","shell.execute_reply":"2022-02-07T18:19:51.120313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The data, shuffled and split between train and test sets:\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint('x_train shape:', x_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n\n## Each image is a 32 x 32 x 3 numpy array\nprint(x_train[444].shape)\nprint(y_train[444])\n#plt.imshow(x_train[444]);","metadata":{"execution":{"iopub.status.busy":"2022-02-07T18:20:01.069259Z","iopub.execute_input":"2022-02-07T18:20:01.069561Z","iopub.status.idle":"2022-02-07T18:20:09.681503Z","shell.execute_reply.started":"2022-02-07T18:20:01.069529Z","shell.execute_reply":"2022-02-07T18:20:09.680385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical\n\nnum_classes = 10\n\ny_train = to_categorical(y_train, num_classes)\ny_test = to_categorical(y_test, num_classes)\n\n# now instead of classes described by an integer between 0-9 we have a vector with a 1 in the (Pythonic) 9th position\nprint(y_train[444])\n\n# As before, let's make everything float and scale\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255\nx_test /= 255\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T18:20:09.687842Z","iopub.execute_input":"2022-02-07T18:20:09.688483Z","iopub.status.idle":"2022-02-07T18:20:10.052644Z","shell.execute_reply.started":"2022-02-07T18:20:09.688423Z","shell.execute_reply":"2022-02-07T18:20:10.05141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's build model_1: 2-1, 5x5 architecture.\n\nmodel_1 = Sequential()\n\n\n## 5x5 convolution with 2x2 stride and 32 filters\nmodel_1.add(Conv2D(32, (5, 5), strides = (2,2), padding='same',\n                 input_shape=x_train.shape[1:]))\nmodel_1.add(Activation('relu'))\n\n## Another 5x5 convolution with 2x2 stride and 32 filters\nmodel_1.add(Conv2D(64, (5, 5), strides = (2,2)))\nmodel_1.add(Activation('relu'))\n\n## 2x2 max pooling reduces to 3 x 3 x 32\nmodel_1.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_1.add(Dropout(0.2))\n\n## Flatten turns 3x3x32 into 288x1\nmodel_1.add(Flatten())\nmodel_1.add(Dense(256))\nmodel_1.add(Activation('relu'))\nmodel_1.add(Dropout(0.4))\nmodel_1.add(Dense(num_classes))\nmodel_1.add(Activation('softmax'))\n\nmodel_1.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T18:49:58.844354Z","iopub.execute_input":"2022-02-07T18:49:58.844713Z","iopub.status.idle":"2022-02-07T18:49:58.93154Z","shell.execute_reply.started":"2022-02-07T18:49:58.844681Z","shell.execute_reply":"2022-02-07T18:49:58.930588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We still have 181K parameters, even though this is a \"small\" model.\n","metadata":{}},{"cell_type":"code","source":"batch_size = 32\n\n# initiate RMSprop optimizer\nopt = RMSprop(lr=0.0005, decay=1e-6)\n\n# Let's train the model using RMSprop\nmodel_1.compile(loss='categorical_crossentropy',\n              optimizer=opt,\n              metrics=['accuracy'])\n\n#t = time.time()\nmodel_1.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=10,\n              validation_data=(x_test, y_test),\n              shuffle=True)\n\n#print('elpsed time is', time.time()-t)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T18:50:02.576027Z","iopub.execute_input":"2022-02-07T18:50:02.576406Z","iopub.status.idle":"2022-02-07T18:52:26.713973Z","shell.execute_reply.started":"2022-02-07T18:50:02.576364Z","shell.execute_reply":"2022-02-07T18:52:26.712893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Exercise\nOur previous model had the structure:\n\nConv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n\n(with appropriate activation functions and dropouts)\n\n1. Build a more complicated model with the following pattern:\n- Conv -> Conv -> MaxPool -> Conv -> Conv -> MaxPool -> (Flatten) -> Dense -> Final Classification\n\n- Use strides of 1 for all convolutional layers.\n\n2. How many parameters does your model have?  How does that compare to the previous model?\n\n3. Train it for 5 epochs.  What do you notice about the training time, loss and accuracy numbers (on both the training and validation sets)?\n\n5. Try different structures and run times, and see how accurate your model can be.\n","metadata":{}},{"cell_type":"code","source":"# Let's build model_2: 2-1-2-1, 3x3 architecture\n\nmodel_2 = Sequential()\n\nmodel_2.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=x_train.shape[1:]))\nmodel_2.add(Activation('relu'))\nmodel_2.add(Conv2D(32, (3, 3)))\nmodel_2.add(Activation('relu'))\nmodel_2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2.add(Dropout(0.2))\n\nmodel_2.add(Conv2D(64, (3, 3), padding='same'))\nmodel_2.add(Activation('relu'))\nmodel_2.add(Conv2D(64, (3, 3)))\nmodel_2.add(Activation('relu'))\nmodel_2.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_2.add(Dropout(0.2))\n\nmodel_2.add(Flatten())\nmodel_2.add(Dense(512))\nmodel_2.add(Activation('relu'))\nmodel_2.add(Dropout(0.4))\nmodel_2.add(Dense(num_classes))\nmodel_2.add(Activation('softmax'))\n\nmodel_2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T18:27:16.863415Z","iopub.execute_input":"2022-02-07T18:27:16.864065Z","iopub.status.idle":"2022-02-07T18:27:17.030039Z","shell.execute_reply.started":"2022-02-07T18:27:16.863943Z","shell.execute_reply":"2022-02-07T18:27:17.029011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initiate RMSprop optimizer\nopt_2 = RMSprop(lr=0.0005)\n\n# Let's train the model using RMSprop\nmodel_2.compile(loss='categorical_crossentropy',\n              optimizer=opt_2,\n              metrics=['accuracy'])\n\nmodel_2.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=10,\n              validation_data=(x_test, y_test),\n              shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T18:24:49.327109Z","iopub.execute_input":"2022-02-07T18:24:49.327402Z","iopub.status.idle":"2022-02-07T18:27:13.641722Z","shell.execute_reply.started":"2022-02-07T18:24:49.327371Z","shell.execute_reply":"2022-02-07T18:27:13.640739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's build model_3: 2-1-2-1-1, 3x3 architecture, lower dropouts\n\nmodel_3 = Sequential()\n\nmodel_3.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape=x_train.shape[1:]))\nmodel_3.add(Activation('relu'))\nmodel_3.add(Conv2D(32, (3, 3)))\nmodel_3.add(Activation('relu'))\nmodel_3.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_3.add(Dropout(0.2))\n\nmodel_3.add(Conv2D(64, (3, 3), padding='same'))\nmodel_3.add(Activation('relu'))\nmodel_3.add(Conv2D(64, (3, 3)))\nmodel_3.add(Activation('relu'))\nmodel_3.add(MaxPooling2D(pool_size=(2, 2)))\nmodel_3.add(Dropout(0.2))\n\nmodel_3.add(Conv2D(128, (3, 3)))\nmodel_3.add(Activation('relu'))\n#model_3.add(MaxPooling2D(pool_size=(2, 2)))\n#model_3.add(Dropout(0.2))\n\nmodel_3.add(Flatten())\nmodel_3.add(Dense(512))\nmodel_3.add(Activation('relu'))\nmodel_3.add(Dropout(0.4))\nmodel_3.add(Dense(num_classes))\nmodel_3.add(Activation('softmax'))\n\nmodel_3.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T18:38:34.343744Z","iopub.execute_input":"2022-02-07T18:38:34.344063Z","iopub.status.idle":"2022-02-07T18:38:34.490793Z","shell.execute_reply.started":"2022-02-07T18:38:34.344023Z","shell.execute_reply":"2022-02-07T18:38:34.489666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# initiate RMSprop optimizer\nopt_3 = RMSprop(lr=0.0005)\n\n# Let's train the model using RMSprop\nmodel_3.compile(loss='categorical_crossentropy',\n              optimizer=opt_3,\n              metrics=['accuracy'])\n\nmodel_3.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=10,\n              validation_data=(x_test, y_test),\n              shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-07T18:38:37.847434Z","iopub.execute_input":"2022-02-07T18:38:37.84774Z","iopub.status.idle":"2022-02-07T18:40:43.230826Z","shell.execute_reply.started":"2022-02-07T18:38:37.847707Z","shell.execute_reply":"2022-02-07T18:40:43.229827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n### Machine Learning Foundation (C) 2020 IBM Corporation","metadata":{}}]}