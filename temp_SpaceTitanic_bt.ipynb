{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"##################################################################################################\n### This script is ML Classification template, which should be applicable to most MLC projects ###\n##################################################################################################\n\n\"\"\"Structure of the script:\n1.  Load all needed libraries and functions.\n2.  Load data, do preliminary data exploration.\n2.1 [Optional] Create more variables, delete variables.\n3.  Deal with missing values, transform skewed variables.\n4.  Trnasform features depending on their type. OHC.\n5.  Create subsamples.\n6.  Do scaling.\n7.  Fit models, selecting hyperparameters via CV grid search.\n8.  Evaluate performance of the selected models on test sample.\n\"\"\"\n\n### 1.Load main libraries ###\n\nimport time\nimport numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn import svm\nfrom sklearn.preprocessing import LabelBinarizer, LabelEncoder, OrdinalEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom xgboost import XGBRegressor, XGBClassifier\n\n\n\npd.set_option('display.max_columns', 20)\npd.set_option('mode.chained_assignment', None)\npd.set_option('display.expand_frame_repr', False)\n\n# Turn off warnings. Be warned!\ndef warn(*args, **kwargs):\n    pass\nimport warnings\nwarnings.warn = warn\n\ndef draw_histograms(df, variables, n_rows, n_cols):\n    # stolen from https://stackoverflow.com/questions/29530355/plotting-multiple-histograms-in-grid\n    fig=plt.figure()\n    for i, var_name in enumerate(variables):\n        ax=fig.add_subplot(n_rows,n_cols,i+1)\n        df[var_name].hist(bins=10,ax=ax)\n        ax.set_title(var_name+\" Distribution\")\n    fig.tight_layout()  \n    plt.show()\n\n### 2.Load data ###\n\ntime1 = time.time()\n\npath = '../input/spaceship-titanic/train.csv'\ntrain = pd.read_csv(path) \nprint(train.shape)\ntrain.head(2)\n\ntest_data=pd.read_csv('../input/spaceship-titanic/test.csv')\n\nprint(train.shape, test_data.shape)\ntest = test_data.copy()\ntrain['sample']='train'\ntest['Transported'] = np.nan\ntest['sample']='test'\n\ndf=pd.concat([train, test])\ndf.reset_index(inplace=True, drop=True)\nprint(df.shape)\ndf.tail(3)\n\nnum_cols = ['Age', 'RoomService', 'FoodCourt', 'ShoppingMall', 'Spa', 'VRDeck']\ncat_cols = ['HomePlanet','CryoSleep','VIP', 'Destination', 'Transported']\n\nprint(df[num_cols].describe())\nprint(df[cat_cols].apply(pd.Series.value_counts))\nprint(df.shape)\n\n# sns.pairplot(df[['Survived', 'Pclass', 'Age', 'Fare']])\n#draw_histograms(df, df.columns, 4, 3)\n\n#%% 2.5 Create more features ###\n\ndf[['Group_Id', 'Passeng_Id']] = df['PassengerId'].str.split('_', 1, expand=True)\ndf[['Deck', 'Room', 'Side']] = df['Cabin'].str.split('/', 2, expand=True)\nprint(df.dtypes)\n\ndf[['Group_Id', 'Passeng_Id', 'Room']] = df[['Group_Id', 'Passeng_Id', 'Room']].apply(pd.to_numeric)\ndf.drop(columns=['Passeng_Id', 'Cabin', 'Group_Id', 'Room', 'Name'], inplace=True)\n\n#%% 3.Deal with missing values ###\n\ndf.info()\n#df.dropna(inplace=True, subset=df.columns.drop(['Transported']))\ndf.shape\n\ndf.fillna(df.median()[num_cols], inplace=True)\ndf['HomePlanet'].fillna(df['HomePlanet'].value_counts().index[0], inplace=True)\ndf['CryoSleep'].fillna(df['CryoSleep'].value_counts().index[0], inplace=True)\ndf['Destination'].fillna(df['Destination'].value_counts().index[0], inplace=True)\ndf['VIP'].fillna(df['VIP'].value_counts().index[0], inplace=True)\ndf['Deck'].fillna(df['Deck'].value_counts().index[0], inplace=True)\ndf['Side'].fillna(df['Side'].value_counts().index[0], inplace=True)\ndf.describe(include='all')\n\n#%% Transform some skewed variables ###\n\ndf['RoomService'] = np.log1p(df.RoomService)\ndf['FoodCourt'] = np.log1p(df.FoodCourt)\ndf['ShoppingMall'] = np.log1p(df.ShoppingMall)\ndf['Spa'] = np.log1p(df.Spa)\ndf['VRDeck'] = np.log1p(df.VRDeck)\n\ndf['CryoSleep'] = df['CryoSleep'].astype(int)\ndf['VIP'] = df['VIP'].astype(int)\ndf.loc[~(df.Transported.isnull()),'Transported'] = df.loc[~(df.Transported.isnull()),'Transported'].astype(int)\ndf.head()\n\n#%% 4.Transform features depending on their type ###\n\n# this is very important for ML application, where there are hundreds of features.\n# If there are less than 20 features, can use standard approach.\n# my approach of tackling one feature a time is not scalable. \n\n# use intuition to trim range or ordinary variables \n# can skip this step in general, since it is not scalable when number of features grows.\n\n# identify binary and categorical variables\ndf_uniques = pd.DataFrame([[i, len(df[i].unique())] for i in df.columns], columns=['Variable', 'Unique Values']).set_index('Variable')\nprint(df_uniques)\n\nbinary_variables = list(df_uniques[df_uniques['Unique Values'] == 2].index)\ncategorical_variables = list(df_uniques[(10 >= df_uniques['Unique Values']) & (df_uniques['Unique Values'] > 2)].index)\nnumeric_variables = list(set(df.columns) - set(categorical_variables) - set(binary_variables))\nprint('Binary variables are ', binary_variables)\nprint('Categorical variables are ', categorical_variables)\nprint('Numeric variables are ', numeric_variables)\n\n# ohc for binary variables #\nlb = LabelBinarizer()\nbinary_variables.remove('sample')\nfor column in binary_variables:\n    df[column] = lb.fit_transform(df[column])\n\n# ohc for categorical variables #\ncategorical_variables.remove('Transported')\ndf = pd.get_dummies(df, columns = categorical_variables, drop_first=True)\n\nprint(df.shape)\nprint(df.head())\nprint(df.dtypes)\n\n# %% 5.Creating subsamples ###\n\ntrain = df[df['sample']=='train'].copy()\ntrain.drop(columns=['sample'], inplace=True)\ntest = df[df['sample']=='test'].copy()\ntest.drop(columns=['sample'], inplace=True)\n\nprint(train.shape)\nprint(test.shape)\ntrain.head(3)\n\n# %% 5.Creating subsamples ###\n\ny_train = train['Transported']\nX_train = train.drop(columns=['Transported'])\nX_test = test.drop(columns=['Transported'])\nprint(X_train.shape)\n\nX_train, X_traintest, y_train, y_traintest = train_test_split(X_train,y_train,test_size=0.1, random_state=6)\n\nX_train_id = X_train.copy()\nX_traintest_id = X_traintest.copy() \nX_test = X_test.copy()\n\nX_train.drop(columns=['PassengerId'], inplace=True)\nX_traintest.drop(columns=['PassengerId'], inplace=True)\nX_test.drop(columns=['PassengerId'], inplace=True)\n\n\nprint(X_train.shape)\nprint(X_traintest.shape)\nprint(X_test.shape)\nX_traintest.head(3)\n\n# 'traintest' is hold-out sample to veify that chosen model indeed works.\n# it is different from 'test', which is truly out of sample.\n\nss = StandardScaler()\nnumeric_variables.remove('PassengerId')\n\nfor column in [numeric_variables]:\n    X_train[column] = ss.fit_transform(X_train[column])\n    X_traintest[column] = ss.transform(X_traintest[column])\n    X_test[column] = ss.transform(X_test[column])\n\n####################\n### 7.Fit models ###\n####################\n\ntime3 = time.time()\n\n#%% KNN ###\n\ngrid_values = dict(n_neighbors=np.arange(10,41,5))\nknnm = KNeighborsClassifier()   \nmodel_knn = GridSearchCV(knnm, param_grid=grid_values, cv = 8)\nmodel_knn.fit(X_train, y_train)\nprint('knn ', model_knn.best_score_, model_knn.best_params_)\n\n\n#%% XGBoost ###\n# run this code only on Kaggle with GPU\n\ntime4 = time.time()\n\nestimator = XGBClassifier(\n    nthread=4,\n    seed=42,\n    use_label_encoder=False\n)\n\nparameters = {\n    'max_depth': range (2, 3, 1),\n    'n_estimators': [400, 500, 600, 800, 1000],\n    'learning_rate': [0.02, 0.03, 0.04]\n}\n\ngrid_search = GridSearchCV(\n    estimator=estimator,\n    param_grid=parameters,\n    scoring = 'roc_auc',\n    n_jobs = -1,\n    cv = 8,\n    verbose=True\n)\n\ngrid_search.fit(X_train, y_train, eval_metric='rmse')\nprint('XGB tree ', grid_search.best_score_, grid_search.best_params_)\n\nxgbc = XGBClassifier(nthread=4, seed=42, use_label_encoder=False,\n                     max_depth=2, n_estimators=400, learning_rate=0.02)\nxgbc.fit(X_train, y_train)\n\n#%% 8.Evaluate performance oos ###\n\nyhat_knn = model_knn.predict(X_traintest)\nyhat_btcv = grid_search.predict(X_traintest)\nyhat_btm = xgbc.predict(X_traintest)\n\nprint('Accuracy of KNN is ', 1-(np.abs(yhat_knn-y_traintest)).mean())\nprint('Accuracy of Boosted Tree cv is ', 1-(np.abs(yhat_btcv-y_traintest)).mean())\nprint('Accuracy of Boosted Tree m is ', 1-(np.abs(yhat_btm-y_traintest)).mean())\n\nprint('Total time is ', time.time()-time1)\n\n# when dealing only with nonmissing data, i reliable get 80.0-80.5% accuracy for svm and rf.","metadata":{"execution":{"iopub.status.busy":"2022-03-31T00:27:00.193390Z","iopub.execute_input":"2022-03-31T00:27:00.193688Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"(8693, 14)\n(8693, 14) (4277, 13)\n(12970, 15)\n                Age   RoomService     FoodCourt  ShoppingMall           Spa        VRDeck\ncount  12700.000000  12707.000000  12681.000000  12664.000000  12686.000000  12702.000000\nmean      28.771969    222.897852    451.961675    174.906033    308.476904    306.789482\nstd       14.387261    647.596664   1584.370747    590.558690   1130.279641   1180.097223\nmin        0.000000      0.000000      0.000000      0.000000      0.000000      0.000000\n25%       19.000000      0.000000      0.000000      0.000000      0.000000      0.000000\n50%       27.000000      0.000000      0.000000      0.000000      0.000000      0.000000\n75%       38.000000     49.000000     77.000000     29.000000     57.000000     42.000000\nmax       79.000000  14327.000000  29813.000000  23492.000000  22408.000000  24133.000000\n               HomePlanet  CryoSleep      VIP  Destination  Transported\nFalse                 NaN     8079.0  12401.0          NaN       4315.0\nTrue                  NaN     4581.0    273.0          NaN       4378.0\n55 Cancri e           NaN        NaN      NaN       2641.0          NaN\nEarth              6865.0        NaN      NaN          NaN          NaN\nEuropa             3133.0        NaN      NaN          NaN          NaN\nMars               2684.0        NaN      NaN          NaN          NaN\nPSO J318.5-22         NaN        NaN      NaN       1184.0          NaN\nTRAPPIST-1e           NaN        NaN      NaN       8871.0          NaN\n(12970, 15)\nPassengerId      object\nHomePlanet       object\nCryoSleep        object\nCabin            object\nDestination      object\nAge             float64\nVIP              object\nRoomService     float64\nFoodCourt       float64\nShoppingMall    float64\nSpa             float64\nVRDeck          float64\nName             object\nTransported     float64\nsample           object\nGroup_Id         object\nPasseng_Id       object\nDeck             object\nRoom             object\nSide             object\ndtype: object\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 12970 entries, 0 to 12969\nData columns (total 15 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   PassengerId   12970 non-null  object \n 1   HomePlanet    12682 non-null  object \n 2   CryoSleep     12660 non-null  object \n 3   Destination   12696 non-null  object \n 4   Age           12700 non-null  float64\n 5   VIP           12674 non-null  object \n 6   RoomService   12707 non-null  float64\n 7   FoodCourt     12681 non-null  float64\n 8   ShoppingMall  12664 non-null  float64\n 9   Spa           12686 non-null  float64\n 10  VRDeck        12702 non-null  float64\n 11  Transported   8693 non-null   float64\n 12  sample        12970 non-null  object \n 13  Deck          12671 non-null  object \n 14  Side          12671 non-null  object \ndtypes: float64(7), object(8)\nmemory usage: 1.5+ MB\n              Unique Values\nVariable                   \nPassengerId           12970\nHomePlanet                3\nCryoSleep                 2\nDestination               3\nAge                      80\nVIP                       2\nRoomService            1578\nFoodCourt              1953\nShoppingMall           1367\nSpa                    1679\nVRDeck                 1642\nTransported               3\nsample                    2\nDeck                      8\nSide                      2\nBinary variables are  ['CryoSleep', 'VIP', 'sample', 'Side']\nCategorical variables are  ['HomePlanet', 'Destination', 'Transported', 'Deck']\nNumeric variables are  ['Spa', 'ShoppingMall', 'PassengerId', 'Age', 'FoodCourt', 'VRDeck', 'RoomService']\n(12970, 23)\n  PassengerId  CryoSleep   Age  VIP  RoomService  FoodCourt  ShoppingMall       Spa    VRDeck  Transported  ... HomePlanet_Mars  Destination_PSO J318.5-22  Destination_TRAPPIST-1e  Deck_B  Deck_C  Deck_D  Deck_E  Deck_F  Deck_G  Deck_T\n0     0001_01          0  39.0    0     0.000000   0.000000      0.000000  0.000000  0.000000          0.0  ...               0                          0                        1       1       0       0       0       0       0       0\n1     0002_01          0  24.0    0     4.700480   2.302585      3.258097  6.309918  3.806662          1.0  ...               0                          0                        1       0       0       0       0       1       0       0\n2     0003_01          0  58.0    1     3.784190   8.182280      0.000000  8.812248  3.912023          0.0  ...               0                          0                        1       0       0       0       0       0       0       0\n3     0003_02          0  33.0    0     0.000000   7.157735      5.918894  8.110728  5.267858          0.0  ...               0                          0                        1       0       0       0       0       0       0       0\n4     0004_01          0  16.0    0     5.717028   4.262680      5.023881  6.338594  1.098612          1.0  ...               0                          0                        1       0       0       0       0       1       0       0\n\n[5 rows x 23 columns]\nPassengerId                   object\nCryoSleep                      int64\nAge                          float64\nVIP                            int64\nRoomService                  float64\nFoodCourt                    float64\nShoppingMall                 float64\nSpa                          float64\nVRDeck                       float64\nTransported                  float64\nsample                        object\nSide                           int64\nHomePlanet_Europa              uint8\nHomePlanet_Mars                uint8\nDestination_PSO J318.5-22      uint8\nDestination_TRAPPIST-1e        uint8\nDeck_B                         uint8\nDeck_C                         uint8\nDeck_D                         uint8\nDeck_E                         uint8\nDeck_F                         uint8\nDeck_G                         uint8\nDeck_T                         uint8\ndtype: object\n(8693, 22)\n(4277, 22)\n(8693, 21)\n(7823, 20)\n(870, 20)\n(4277, 20)\nknn  0.7898523138525556 {'n_neighbors': 25}\nFitting 8 folds for each of 15 candidates, totalling 120 fits\n","output_type":"stream"}]},{"cell_type":"code","source":"xgbc = XGBClassifier(nthread=4, seed=42, use_label_encoder=False,\n                     max_depth=2, n_estimators=800, learning_rate=0.03)\nxgbc.fit(X_train, y_train)\nyhat_btm = xgbc.predict(X_traintest)\nprint('Accuracy of Boosted Tree m is ', 1-(np.abs(yhat_btm-y_traintest)).mean())","metadata":{"execution":{"iopub.status.busy":"2022-03-31T00:26:38.263462Z","iopub.execute_input":"2022-03-31T00:26:38.263733Z","iopub.status.idle":"2022-03-31T00:26:42.944924Z","shell.execute_reply.started":"2022-03-31T00:26:38.263703Z","shell.execute_reply":"2022-03-31T00:26:42.944089Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"[00:26:38] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\nAccuracy of Boosted Tree m is  0.8011494252873563\n","output_type":"stream"}]},{"cell_type":"code","source":"# here I will add ANN\n\nfrom keras.models  import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.optimizers import Adam, SGD, RMSprop\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nmodel_2 = Sequential()\nmodel_2.add(Dense(50, input_shape=(X_train.shape[1],), activation=\"relu\"))\nmodel_2.add(Dropout(0.4))\nmodel_2.add(BatchNormalization())\nmodel_2.add(Dense(50, input_shape=(X_train.shape[1],), activation=\"relu\"))\nmodel_2.add(Dropout(0.4))\nmodel_2.add(BatchNormalization())\nmodel_2.add(Dense(10, activation=\"relu\"))\nmodel_2.add(Dropout(0.4))\nmodel_2.add(BatchNormalization())\nmodel_2.add(Dense(1, activation=\"sigmoid\"))\n\nes = EarlyStopping(monitor='val_loss', patience=20)\n\nmodel_2.compile(optimizer='adam', loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\nrun_hist_2 = model_2.fit(X_train, y_train, validation_data=(X_traintest, y_traintest), epochs=300, callbacks=[es])\n","metadata":{"execution":{"iopub.status.busy":"2022-03-31T00:17:02.501150Z","iopub.execute_input":"2022-03-31T00:17:02.502077Z","iopub.status.idle":"2022-03-31T00:19:11.183302Z","shell.execute_reply.started":"2022-03-31T00:17:02.502036Z","shell.execute_reply":"2022-03-31T00:19:11.182534Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Epoch 1/300\n245/245 [==============================] - 2s 5ms/step - loss: 0.6392 - accuracy: 0.6817 - val_loss: 0.5340 - val_accuracy: 0.7448\nEpoch 2/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.5563 - accuracy: 0.7331 - val_loss: 0.5106 - val_accuracy: 0.7494\nEpoch 3/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.5386 - accuracy: 0.7445 - val_loss: 0.4976 - val_accuracy: 0.7621\nEpoch 4/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.5204 - accuracy: 0.7514 - val_loss: 0.4905 - val_accuracy: 0.7609\nEpoch 5/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.5085 - accuracy: 0.7604 - val_loss: 0.4831 - val_accuracy: 0.7632\nEpoch 6/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.5006 - accuracy: 0.7679 - val_loss: 0.4808 - val_accuracy: 0.7598\nEpoch 7/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4955 - accuracy: 0.7642 - val_loss: 0.4758 - val_accuracy: 0.7667\nEpoch 8/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4909 - accuracy: 0.7722 - val_loss: 0.4719 - val_accuracy: 0.7747\nEpoch 9/300\n245/245 [==============================] - 1s 6ms/step - loss: 0.4879 - accuracy: 0.7730 - val_loss: 0.4690 - val_accuracy: 0.7736\nEpoch 10/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4922 - accuracy: 0.7699 - val_loss: 0.4674 - val_accuracy: 0.7747\nEpoch 11/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4870 - accuracy: 0.7686 - val_loss: 0.4679 - val_accuracy: 0.7747\nEpoch 12/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4804 - accuracy: 0.7732 - val_loss: 0.4645 - val_accuracy: 0.7770\nEpoch 13/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4828 - accuracy: 0.7778 - val_loss: 0.4641 - val_accuracy: 0.7770\nEpoch 14/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4808 - accuracy: 0.7777 - val_loss: 0.4594 - val_accuracy: 0.7805\nEpoch 15/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4741 - accuracy: 0.7841 - val_loss: 0.4567 - val_accuracy: 0.7816\nEpoch 16/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4806 - accuracy: 0.7757 - val_loss: 0.4551 - val_accuracy: 0.7805\nEpoch 17/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4761 - accuracy: 0.7818 - val_loss: 0.4587 - val_accuracy: 0.7724\nEpoch 18/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4712 - accuracy: 0.7832 - val_loss: 0.4557 - val_accuracy: 0.7839\nEpoch 19/300\n245/245 [==============================] - 2s 8ms/step - loss: 0.4647 - accuracy: 0.7840 - val_loss: 0.4534 - val_accuracy: 0.7839\nEpoch 20/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4721 - accuracy: 0.7822 - val_loss: 0.4507 - val_accuracy: 0.7874\nEpoch 21/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4733 - accuracy: 0.7824 - val_loss: 0.4499 - val_accuracy: 0.7862\nEpoch 22/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4658 - accuracy: 0.7877 - val_loss: 0.4476 - val_accuracy: 0.7920\nEpoch 23/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4738 - accuracy: 0.7870 - val_loss: 0.4484 - val_accuracy: 0.7828\nEpoch 24/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4727 - accuracy: 0.7769 - val_loss: 0.4508 - val_accuracy: 0.7874\nEpoch 25/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4702 - accuracy: 0.7829 - val_loss: 0.4437 - val_accuracy: 0.7885\nEpoch 26/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4600 - accuracy: 0.7841 - val_loss: 0.4451 - val_accuracy: 0.7862\nEpoch 27/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4639 - accuracy: 0.7829 - val_loss: 0.4436 - val_accuracy: 0.7908\nEpoch 28/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.7819 - val_loss: 0.4454 - val_accuracy: 0.7828\nEpoch 29/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4609 - accuracy: 0.7872 - val_loss: 0.4404 - val_accuracy: 0.7908\nEpoch 30/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4678 - accuracy: 0.7864 - val_loss: 0.4414 - val_accuracy: 0.7862\nEpoch 31/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4618 - accuracy: 0.7790 - val_loss: 0.4428 - val_accuracy: 0.7920\nEpoch 32/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4628 - accuracy: 0.7883 - val_loss: 0.4434 - val_accuracy: 0.7943\nEpoch 33/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4602 - accuracy: 0.7888 - val_loss: 0.4432 - val_accuracy: 0.7885\nEpoch 34/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.7860 - val_loss: 0.4371 - val_accuracy: 0.7954\nEpoch 35/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4589 - accuracy: 0.7892 - val_loss: 0.4402 - val_accuracy: 0.7920\nEpoch 36/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4597 - accuracy: 0.7907 - val_loss: 0.4417 - val_accuracy: 0.7885\nEpoch 37/300\n245/245 [==============================] - 1s 6ms/step - loss: 0.4643 - accuracy: 0.7867 - val_loss: 0.4397 - val_accuracy: 0.7931\nEpoch 38/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4648 - accuracy: 0.7846 - val_loss: 0.4393 - val_accuracy: 0.7897\nEpoch 39/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4678 - accuracy: 0.7905 - val_loss: 0.4389 - val_accuracy: 0.7920\nEpoch 40/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4588 - accuracy: 0.7936 - val_loss: 0.4323 - val_accuracy: 0.7943\nEpoch 41/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4594 - accuracy: 0.7909 - val_loss: 0.4328 - val_accuracy: 0.7931\nEpoch 42/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4593 - accuracy: 0.7914 - val_loss: 0.4352 - val_accuracy: 0.7908\nEpoch 43/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4626 - accuracy: 0.7884 - val_loss: 0.4355 - val_accuracy: 0.7885\nEpoch 44/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4547 - accuracy: 0.7897 - val_loss: 0.4344 - val_accuracy: 0.7908\nEpoch 45/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4561 - accuracy: 0.7943 - val_loss: 0.4372 - val_accuracy: 0.7931\nEpoch 46/300\n245/245 [==============================] - 2s 7ms/step - loss: 0.4537 - accuracy: 0.7938 - val_loss: 0.4309 - val_accuracy: 0.7943\nEpoch 47/300\n245/245 [==============================] - 1s 6ms/step - loss: 0.4508 - accuracy: 0.7915 - val_loss: 0.4316 - val_accuracy: 0.7989\nEpoch 48/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4562 - accuracy: 0.7891 - val_loss: 0.4319 - val_accuracy: 0.8000\nEpoch 49/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4508 - accuracy: 0.7945 - val_loss: 0.4309 - val_accuracy: 0.7931\nEpoch 50/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4594 - accuracy: 0.7895 - val_loss: 0.4298 - val_accuracy: 0.7943\nEpoch 51/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4491 - accuracy: 0.7927 - val_loss: 0.4333 - val_accuracy: 0.7977\nEpoch 52/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4538 - accuracy: 0.7932 - val_loss: 0.4323 - val_accuracy: 0.7966\nEpoch 53/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4550 - accuracy: 0.7904 - val_loss: 0.4316 - val_accuracy: 0.7908\nEpoch 54/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4531 - accuracy: 0.7896 - val_loss: 0.4348 - val_accuracy: 0.7943\nEpoch 55/300\n245/245 [==============================] - 1s 6ms/step - loss: 0.4505 - accuracy: 0.7938 - val_loss: 0.4352 - val_accuracy: 0.7920\nEpoch 56/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4502 - accuracy: 0.7955 - val_loss: 0.4330 - val_accuracy: 0.7920\nEpoch 57/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4537 - accuracy: 0.7936 - val_loss: 0.4323 - val_accuracy: 0.7897\nEpoch 58/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4553 - accuracy: 0.7927 - val_loss: 0.4324 - val_accuracy: 0.7943\nEpoch 59/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4593 - accuracy: 0.7877 - val_loss: 0.4416 - val_accuracy: 0.7885\nEpoch 60/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4524 - accuracy: 0.7906 - val_loss: 0.4346 - val_accuracy: 0.7931\nEpoch 61/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4492 - accuracy: 0.7936 - val_loss: 0.4352 - val_accuracy: 0.7908\nEpoch 62/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4527 - accuracy: 0.7933 - val_loss: 0.4312 - val_accuracy: 0.7885\nEpoch 63/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4470 - accuracy: 0.7928 - val_loss: 0.4342 - val_accuracy: 0.7885\nEpoch 64/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4584 - accuracy: 0.7899 - val_loss: 0.4372 - val_accuracy: 0.7931\nEpoch 65/300\n245/245 [==============================] - 1s 6ms/step - loss: 0.4426 - accuracy: 0.7948 - val_loss: 0.4318 - val_accuracy: 0.7943\nEpoch 66/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4531 - accuracy: 0.7910 - val_loss: 0.4341 - val_accuracy: 0.7885\nEpoch 67/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4496 - accuracy: 0.7915 - val_loss: 0.4320 - val_accuracy: 0.7908\nEpoch 68/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4524 - accuracy: 0.7906 - val_loss: 0.4277 - val_accuracy: 0.7989\nEpoch 69/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4498 - accuracy: 0.7923 - val_loss: 0.4323 - val_accuracy: 0.7897\nEpoch 70/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4509 - accuracy: 0.7968 - val_loss: 0.4336 - val_accuracy: 0.7943\nEpoch 71/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4490 - accuracy: 0.7948 - val_loss: 0.4294 - val_accuracy: 0.7966\nEpoch 72/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4514 - accuracy: 0.7909 - val_loss: 0.4325 - val_accuracy: 0.7954\nEpoch 73/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4583 - accuracy: 0.7924 - val_loss: 0.4314 - val_accuracy: 0.7874\nEpoch 74/300\n245/245 [==============================] - 2s 8ms/step - loss: 0.4452 - accuracy: 0.7909 - val_loss: 0.4323 - val_accuracy: 0.7931\nEpoch 75/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4476 - accuracy: 0.7924 - val_loss: 0.4364 - val_accuracy: 0.7885\nEpoch 76/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4460 - accuracy: 0.7905 - val_loss: 0.4356 - val_accuracy: 0.7966\nEpoch 77/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4447 - accuracy: 0.7991 - val_loss: 0.4333 - val_accuracy: 0.7954\nEpoch 78/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4482 - accuracy: 0.7915 - val_loss: 0.4330 - val_accuracy: 0.8011\nEpoch 79/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4544 - accuracy: 0.7932 - val_loss: 0.4301 - val_accuracy: 0.7989\nEpoch 80/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4502 - accuracy: 0.7883 - val_loss: 0.4351 - val_accuracy: 0.7885\nEpoch 81/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4491 - accuracy: 0.7914 - val_loss: 0.4300 - val_accuracy: 0.7931\nEpoch 82/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4413 - accuracy: 0.7964 - val_loss: 0.4342 - val_accuracy: 0.7920\nEpoch 83/300\n245/245 [==============================] - 1s 6ms/step - loss: 0.4517 - accuracy: 0.7920 - val_loss: 0.4353 - val_accuracy: 0.7908\nEpoch 84/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4508 - accuracy: 0.7938 - val_loss: 0.4304 - val_accuracy: 0.8000\nEpoch 85/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4479 - accuracy: 0.7927 - val_loss: 0.4330 - val_accuracy: 0.7908\nEpoch 86/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4475 - accuracy: 0.7965 - val_loss: 0.4319 - val_accuracy: 0.7920\nEpoch 87/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4463 - accuracy: 0.7927 - val_loss: 0.4276 - val_accuracy: 0.7966\nEpoch 88/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4522 - accuracy: 0.7886 - val_loss: 0.4293 - val_accuracy: 0.7931\nEpoch 89/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4438 - accuracy: 0.7962 - val_loss: 0.4283 - val_accuracy: 0.7943\nEpoch 90/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4476 - accuracy: 0.7915 - val_loss: 0.4329 - val_accuracy: 0.7989\nEpoch 91/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4510 - accuracy: 0.7960 - val_loss: 0.4291 - val_accuracy: 0.7943\nEpoch 92/300\n245/245 [==============================] - 1s 6ms/step - loss: 0.4477 - accuracy: 0.7938 - val_loss: 0.4322 - val_accuracy: 0.7943\nEpoch 93/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4487 - accuracy: 0.7932 - val_loss: 0.4324 - val_accuracy: 0.7931\nEpoch 94/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4444 - accuracy: 0.7959 - val_loss: 0.4321 - val_accuracy: 0.7931\nEpoch 95/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4579 - accuracy: 0.7934 - val_loss: 0.4330 - val_accuracy: 0.7989\nEpoch 96/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4494 - accuracy: 0.7946 - val_loss: 0.4316 - val_accuracy: 0.7954\nEpoch 97/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4442 - accuracy: 0.7993 - val_loss: 0.4303 - val_accuracy: 0.7920\nEpoch 98/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4496 - accuracy: 0.7957 - val_loss: 0.4338 - val_accuracy: 0.7943\nEpoch 99/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4458 - accuracy: 0.7943 - val_loss: 0.4287 - val_accuracy: 0.7943\nEpoch 100/300\n245/245 [==============================] - 1s 4ms/step - loss: 0.4490 - accuracy: 0.7925 - val_loss: 0.4302 - val_accuracy: 0.7966\nEpoch 101/300\n245/245 [==============================] - 2s 7ms/step - loss: 0.4488 - accuracy: 0.7945 - val_loss: 0.4309 - val_accuracy: 0.7920\nEpoch 102/300\n245/245 [==============================] - 1s 6ms/step - loss: 0.4531 - accuracy: 0.7919 - val_loss: 0.4300 - val_accuracy: 0.7954\nEpoch 103/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4489 - accuracy: 0.7976 - val_loss: 0.4284 - val_accuracy: 0.7966\nEpoch 104/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4504 - accuracy: 0.7928 - val_loss: 0.4293 - val_accuracy: 0.7920\nEpoch 105/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4482 - accuracy: 0.7905 - val_loss: 0.4300 - val_accuracy: 0.7897\nEpoch 106/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4464 - accuracy: 0.7941 - val_loss: 0.4316 - val_accuracy: 0.7943\nEpoch 107/300\n245/245 [==============================] - 1s 5ms/step - loss: 0.4477 - accuracy: 0.7891 - val_loss: 0.4335 - val_accuracy: 0.7954\n","output_type":"stream"}]},{"cell_type":"code","source":"### Export results ###\n\nyhat_btm = xgbc.predict(X_test).astype(int)\n\nreplacements = {1:True, 0:False}\nreplacer = replacements.get\n\nyhat_btm = [replacer(n, n) for n in yhat_btm]","metadata":{"execution":{"iopub.status.busy":"2022-03-31T00:01:28.976201Z","iopub.execute_input":"2022-03-31T00:01:28.976487Z","iopub.status.idle":"2022-03-31T00:01:29.013165Z","shell.execute_reply.started":"2022-03-31T00:01:28.976457Z","shell.execute_reply":"2022-03-31T00:01:29.012405Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"submission_df_bt = pd.DataFrame({'PassengerId': test.PassengerId, 'Transported': yhat_btm}, columns=['PassengerId', 'Transported'])\nsubmission_df_bt.to_csv('submissions_SpaceTitanic_i1_bt.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-31T00:01:55.836522Z","iopub.execute_input":"2022-03-31T00:01:55.837095Z","iopub.status.idle":"2022-03-31T00:01:55.855925Z","shell.execute_reply.started":"2022-03-31T00:01:55.837054Z","shell.execute_reply":"2022-03-31T00:01:55.854972Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"os.chdir(r'/kaggle/working')\n\nfrom IPython.display import FileLink\nFileLink(r'submissions_SpaceTitanic_i1_bt.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-31T00:01:58.094141Z","iopub.execute_input":"2022-03-31T00:01:58.094404Z","iopub.status.idle":"2022-03-31T00:01:58.103426Z","shell.execute_reply.started":"2022-03-31T00:01:58.094375Z","shell.execute_reply":"2022-03-31T00:01:58.102408Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/submissions_SpaceTitanic_i1_bt.csv","text/html":"<a href='submissions_SpaceTitanic_i1_bt.csv' target='_blank'>submissions_SpaceTitanic_i1_bt.csv</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"FileLink(r'submissions_Titanic_i10_rf1.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%% XGBoost ###\n# run this code only on Kaggle with GPU\n\ntime4 = time.time()\n\nestimator = XGBClassifier(\n    nthread=4,\n    seed=42,\n    use_label_encoder=False\n)\n\nparameters = {\n    'max_depth': range (2, 4, 1),\n    'n_estimators': range(50, 301, 50),\n    'learning_rate': [0.01, 0.03, 0.05]\n}\n\ngrid_search = GridSearchCV(\n    estimator=estimator,\n    param_grid=parameters,\n    scoring = 'roc_auc',\n    n_jobs = -1,\n    cv = 8,\n    verbose=True\n)\n\ngrid_search.fit(X_train, y_train, eval_metric='rmse')\nprint(grid_search.best_score_, grid_search.best_params_)\nprint('XGB model time is ', time.time()-time4)","metadata":{},"execution_count":null,"outputs":[]}]}